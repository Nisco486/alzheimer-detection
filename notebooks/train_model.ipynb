{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896154ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for data on the Remote Server...\n",
      "\n",
      "üìä Total Images Found on Server: 0\n",
      "‚ùå PROBLEM DETECTED: No images found on this server.\n",
      "\n",
      "üí° EXPLANATION:\n",
      "   You are running this notebook on a Remote GPU Server (Linux).\n",
      "   But your files are likely on your Local Computer (Windows).\n",
      "   The server cannot see your local files automatically.\n",
      "\n",
      "üöÄ SOLUTION:\n",
      "   1. Zip your 'raw' folder on your computer.\n",
      "   2. Drag and drop the 'raw.zip' file into the file list on the left (in VS Code or Colab interface).\n",
      "   3. Run the next cell to unzip it.\n"
     ]
    }
   ],
   "source": [
    "# üîç DATA DIAGNOSTIC TOOL\n",
    "import os\n",
    "\n",
    "print(\"Checking for data on the Remote Server...\")\n",
    "\n",
    "# 1. Count actual images\n",
    "image_count = 0\n",
    "found_files = []\n",
    "\n",
    "# Walk through current directory and /content to find ANY jpg/png\n",
    "search_dirs = ['.', '/content']\n",
    "for search_dir in search_dirs:\n",
    "    if os.path.exists(search_dir):\n",
    "        for root, dirs, files in os.walk(search_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    image_count += 1\n",
    "                    if len(found_files) < 3:\n",
    "                        found_files.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"\\nüìä Total Images Found on Server: {image_count}\")\n",
    "\n",
    "if image_count == 0:\n",
    "    print(\"‚ùå PROBLEM DETECTED: No images found on this server.\")\n",
    "    print(\"\\nüí° EXPLANATION:\")\n",
    "    print(\"   You are running this notebook on a Remote GPU Server (Linux).\")\n",
    "    print(\"   But your files are likely on your Local Computer (Windows).\")\n",
    "    print(\"   The server cannot see your local files automatically.\")\n",
    "    print(\"\\nüöÄ SOLUTION:\")\n",
    "    print(\"   1. Zip your 'raw' folder on your computer.\")\n",
    "    print(\"   2. Drag and drop the 'raw.zip' file into the file list on the left (in VS Code or Colab interface).\")\n",
    "    print(\"   3. Run the next cell to unzip it.\")\n",
    "    \n",
    "    data_root = None\n",
    "else:\n",
    "    print(\"‚úÖ Images found! attempting to locate root folder...\")\n",
    "    # Attempt to derive data_root from the first found file\n",
    "    # e.g. /content/data/raw/Non Demented/img1.jpg -> /content/data/raw\n",
    "    first_img = found_files[0]\n",
    "    # Go up two levels\n",
    "    parent = os.path.dirname(first_img) # Non Demented\n",
    "    grandparent = os.path.dirname(parent) # raw\n",
    "    data_root = grandparent\n",
    "    print(f\"üìÇ Derived Data Root: {data_root}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be4652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Looking for raw.zip...\n",
      "‚ùå 'raw.zip' NOT FOUND.\n",
      "   Checked CWD: /content\n"
     ]
    }
   ],
   "source": [
    "# üõ†Ô∏è SMART UNZIP TOOL\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Possible locations where raw.zip might be suitable\n",
    "potential_zips = [\n",
    "    'raw.zip', \n",
    "    'notebooks/raw.zip',\n",
    "    '../raw.zip',\n",
    "    '/content/raw.zip',\n",
    "    '/content/notebooks/raw.zip'\n",
    "]\n",
    "\n",
    "found_zip = None\n",
    "print(\"üîç Looking for raw.zip...\")\n",
    "for p in potential_zips:\n",
    "    if os.path.exists(p):\n",
    "        found_zip = p\n",
    "        print(f\"‚úÖ Found zip file at: {found_zip}\")\n",
    "        break\n",
    "\n",
    "if found_zip:\n",
    "    # Determine extraction path. If we are in 'notebooks', extract to '../data/raw' or 'data/raw' depending on structure\n",
    "    # Safest bet: Extract to a known absolute data dir or relative 'data/raw'\n",
    "    extract_to = 'data/raw'\n",
    "    \n",
    "    # If the zip is in 'notebooks/', we might want to extract to '../data/raw' if we are in project root\n",
    "    # BUT, let's stick to current directory 'data/raw' to be safe and use that as root.\n",
    "    \n",
    "    print(f\"üì¶ Extracting to '{extract_to}'...\")\n",
    "    os.makedirs(extract_to, exist_ok=True)\n",
    "    \n",
    "    with zipfile.ZipFile(found_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_to)\n",
    "        \n",
    "    print(\"‚úÖ Extraction Complete.\")\n",
    "    \n",
    "    # Verify and Set Root\n",
    "    if os.path.exists(os.path.join(extract_to, 'Data')):\n",
    "        data_root = os.path.join(extract_to, 'Data')\n",
    "        print(f\"üìÇ Data Root set to inner folder: {data_root}\")\n",
    "    elif os.path.exists(os.path.join(extract_to, 'Non Demented')):\n",
    "        data_root = extract_to\n",
    "        print(f\"üìÇ Data Root set to: {data_root}\")\n",
    "    elif os.path.exists(os.path.join(extract_to, 'raw', 'Data')):\n",
    "        data_root = os.path.join(extract_to, 'raw', 'Data')\n",
    "        print(f\"üìÇ Data Root set to nested: {data_root}\")\n",
    "    else:\n",
    "        # Just list what we have\n",
    "        print(f\"‚ö†Ô∏è Extracted, but check structure. Contents of {extract_to}: {os.listdir(extract_to)}\")\n",
    "        data_root = extract_to\n",
    "else:\n",
    "    print(\"‚ùå 'raw.zip' NOT FOUND.\")\n",
    "    print(f\"   Checked CWD: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81227dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m‚úÖ Setup complete\n"
     ]
    }
   ],
   "source": [
    "!pip install -q timm==0.9.12 einops==0.7.0 albumentations==1.3.1 PyYAML==6.0.2 \"numpy<2.0\" matplotlib seaborn scikit-learn pandas\n",
    "import os\n",
    "os.makedirs('data/raw', exist_ok=True)\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96448d83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-910828085.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/seaborn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import seaborn objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrcmod\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpalettes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mrelational\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F401,F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/seaborn/rcmod.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpalettes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/seaborn/palettes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexternal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhusl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdesaturate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_color_cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxkcd_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrayons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_compat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_colormap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/seaborn/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_rgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) from _err\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"warn_copy_on_write\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from pandas._config.config import (\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mpublic_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         public_symbols -= {\n\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"core\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"matrixlib\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnumpy/random/mtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import os, yaml, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "from einops import rearrange\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(f\"PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3da509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Config created\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'data': {\n",
    "        'root_dir': data_root,\n",
    "        'img_size': 224,\n",
    "        'num_classes': 4,\n",
    "        'class_names': [\n",
    "            'Non Demented',\n",
    "            'Very mild Dementia',\n",
    "            'Mild Dementia',\n",
    "            'Moderate Dementia'\n",
    "        ],\n",
    "        'train_split': 0.7,\n",
    "        'val_split': 0.15,\n",
    "        'test_split': 0.15\n",
    "    },\n",
    "    'model': {\n",
    "        'cnn_backbone': 'efficientnet_b3',\n",
    "        'pretrained': True,\n",
    "        'vit_dim': 512,\n",
    "        'vit_depth': 6,\n",
    "        'vit_heads': 8,\n",
    "        'vit_mlp_dim': 2048,\n",
    "        'dropout': 0.2\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 32,\n",
    "        'epochs': 100,\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-4,\n",
    "        'label_smoothing': 0.1,\n",
    "        'class_weights': [1.0, 2.0, 2.5, 3.0],\n",
    "        'early_stopping_patience': 15,\n",
    "        'use_amp': True,\n",
    "        'grad_clip': 1.0\n",
    "    },\n",
    "    'paths': {\n",
    "        'checkpoint_dir': './checkpoints',\n",
    "        'best_model': './checkpoints/best_model.pth'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Config created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6b1f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlzheimerDataset(Dataset):\n",
    "    def __init__(self, paths, labels, transform=None):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.paths[idx]).convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        return image, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045ec69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(train=True):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Rotate(limit=10, p=0.5),\n",
    "            A.Normalize(mean=[0.485]*3, std=[0.229]*3),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "def get_transforms(train=True):\n",
    "    if train:\n",
    "        return A.Compose([\n",
    "            A.Resize(224, 224),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Rotate(limit=10, p=0.5),\n",
    "            A.Normalize(mean=[0.485]*3, std=[0.229]*3),\n",
    "            ToTensorV2()\n",
    "        ])\n",
    "    return A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(mean=[0.485]*3, std=[0.229]*3),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "    return A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Normalize(mean=[0.485]*3, std=[0.229]*3),\n",
    "        ToTensorV2()\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfa4d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Using data directory: C:\\Users\\nisha\\OneDrive\\Documents\\alzheimer-detection\\data\\raw\\Data\n",
      "üìÇ Contents: ['Mild Dementia', 'Moderate Dementia', 'Non Demented', 'Very mild Dementia']\n",
      "\n",
      "üìÇ Scanning dataset:\n",
      "  ‚úÖ Non Demented: 67222 images\n",
      "  ‚úÖ Very mild Dementia: 13725 images\n",
      "  ‚úÖ Mild Dementia: 5002 images\n",
      "  ‚úÖ Moderate Dementia: 488 images\n",
      "\n",
      "‚úÖ Train: 60505, Val: 12966, Test: 12966\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(config):\n",
    "    root = config['data']['root_dir']\n",
    "    classes = config['data']['class_names']\n",
    "\n",
    "    # Check if root directory exists\n",
    "    if not os.path.exists(root):\n",
    "        # Try alternative paths for Colab\n",
    "        possible_paths = [\n",
    "            './data/raw',\n",
    "            '/content/data/raw',\n",
    "            'data/raw',\n",
    "        ]\n",
    "        for path in possible_paths:\n",
    "            if os.path.exists(path):\n",
    "                root = path\n",
    "                print(f\"‚úÖ Found data at: {root}\")\n",
    "                break\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"‚ùå Cannot find data directory. Tried: {possible_paths}\")\n",
    "    \n",
    "    print(f\"\\nüìÇ Using data directory: {os.path.abspath(root)}\")\n",
    "    print(f\"üìÇ Contents: {os.listdir(root)}\\n\")\n",
    "    \n",
    "    image_paths, labels = [], []\n",
    "\n",
    "    print(\"üìÇ Scanning dataset:\")\n",
    "    for idx, cls in enumerate(classes):\n",
    "        cls_dir = os.path.join(root, cls)\n",
    "        \n",
    "        # Debug: show what we're looking for\n",
    "        if not os.path.isdir(cls_dir):\n",
    "            print(f\"‚ùå Missing: {cls_dir}\")\n",
    "            print(f\"   Available folders: {os.listdir(root)}\")\n",
    "            raise FileNotFoundError(f\"‚ùå Missing folder: {cls_dir}\")\n",
    "\n",
    "        imgs = [\n",
    "            os.path.join(cls_dir, f)\n",
    "            for f in os.listdir(cls_dir)\n",
    "            if f.lower().endswith(('.jpg', '.png', '.jpeg'))\n",
    "        ]\n",
    "\n",
    "        print(f\"  ‚úÖ {cls}: {len(imgs)} images\")\n",
    "        image_paths.extend(imgs)\n",
    "        labels.extend([idx] * len(imgs))\n",
    "\n",
    "    image_paths = np.array(image_paths)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        image_paths, labels, test_size=0.15, stratify=labels, random_state=42\n",
    "    )\n",
    "\n",
    "    val_ratio = 0.15 / (0.7 + 0.15)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_temp, y_temp, test_size=val_ratio, stratify=y_temp, random_state=42\n",
    "    )\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test) = prepare_data(config)\n",
    "print(f\"\\n‚úÖ Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fc463d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataloaders ready: 1891 train batches\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    AlzheimerDataset(X_train, y_train, get_transforms(True)),\n",
    "    batch_size=32, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    AlzheimerDataset(X_val, y_val, get_transforms(False)),\n",
    "    batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    AlzheimerDataset(X_test, y_test, get_transforms(False)),\n",
    "    batch_size=32, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dataloaders ready: {len(train_loader)} train batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452ef2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model architecture defined\n"
     ]
    }
   ],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels, embed_dim):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
    "        return x\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, dim, heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.scale = (dim // heads) ** -0.5\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B, N, 3, self.heads, C // self.heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "        \n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        \n",
    "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, mlp_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = MultiHeadAttention(dim, heads, dropout)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_dim), nn.GELU(), nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_dim, dim), nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x))\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, mlp_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([TransformerBlock(dim, heads, mlp_dim, dropout) for _ in range(depth)])\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.norm(x)\n",
    "\n",
    "class HybridCNNViT(nn.Module):\n",
    "    def __init__(self, num_classes=4, cnn_backbone='efficientnet_b3', pretrained=True,\n",
    "                 vit_dim=512, vit_depth=6, vit_heads=8, vit_mlp_dim=2048, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = timm.create_model(cnn_backbone, pretrained=pretrained, features_only=True, out_indices=[-1])\n",
    "        \n",
    "        dummy = torch.randn(1, 3, 224, 224)\n",
    "        with torch.no_grad():\n",
    "            features = self.backbone(dummy)\n",
    "            cnn_out_channels = features[-1].shape[1]\n",
    "            feature_size = features[-1].shape[2]\n",
    "        \n",
    "        self.patch_embed = PatchEmbedding(cnn_out_channels, vit_dim)\n",
    "        num_patches = feature_size * feature_size\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, num_patches + 1, vit_dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, vit_dim))\n",
    "        self.transformer = VisionTransformer(vit_dim, vit_depth, vit_heads, vit_mlp_dim, dropout)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(vit_dim), nn.Linear(vit_dim, vit_dim // 2), nn.GELU(),\n",
    "            nn.Dropout(dropout), nn.Linear(vit_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)[-1]\n",
    "        x = self.patch_embed(features)\n",
    "        B, N, _ = x.shape\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat([cls_tokens, x], dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.transformer(x)\n",
    "        cls_output = x[:, 0]\n",
    "        logits = self.head(cls_output)\n",
    "        return logits\n",
    "\n",
    "print(\"‚úÖ Model architecture defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf896b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• Using device: cuda\n",
      "\n",
      "üìä Model Summary:\n",
      "   Total parameters: 29,366,060\n",
      "   Trainable parameters: 29,366,060\n",
      "   Model size: ~112.02 MB\n",
      "\n",
      "‚úÖ Model initialized successfully!\n",
      "   Input: torch.Size([2, 3, 224, 224]) ‚Üí Output: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üî• Using device: {device}\")\n",
    "\n",
    "model = HybridCNNViT(\n",
    "    num_classes=config['data']['num_classes'],\n",
    "    cnn_backbone=config['model']['cnn_backbone'],\n",
    "    pretrained=config['model']['pretrained'],\n",
    "    vit_dim=config['model']['vit_dim'],\n",
    "    vit_depth=config['model']['vit_depth'],\n",
    "    vit_heads=config['model']['vit_heads'],\n",
    "    vit_mlp_dim=config['model']['vit_mlp_dim'],\n",
    "    dropout=config['model']['dropout']\n",
    ").to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\nüìä Model Summary:\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"   Model size: ~{total_params * 4 / (1024**2):.2f} MB\")\n",
    "\n",
    "# Test forward pass\n",
    "test_input = torch.randn(2, 3, 224, 224).to(device)\n",
    "with torch.no_grad():\n",
    "    test_output = model(test_input)\n",
    "print(f\"\\n‚úÖ Model initialized successfully!\")\n",
    "print(f\"   Input: {test_input.shape} ‚Üí Output: {test_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96182a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training components initialized\n",
      "   Loss: CrossEntropyLoss with class weights\n",
      "   Optimizer: AdamW (lr=0.0001)\n",
      "   Scheduler: CosineAnnealingLR\n",
      "   Mixed Precision: True\n"
     ]
    }
   ],
   "source": [
    "# Loss function with class weights for imbalanced dataset\n",
    "class_weights = torch.tensor(config['training']['class_weights']).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=config['training']['label_smoothing'])\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=config['training']['learning_rate'],\n",
    "    weight_decay=config['training']['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=config['training']['epochs'],\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = GradScaler() if config['training']['use_amp'] else None\n",
    "\n",
    "print(\"‚úÖ Training components initialized\")\n",
    "print(f\"   Loss: CrossEntropyLoss with class weights\")\n",
    "print(f\"   Optimizer: AdamW (lr={config['training']['learning_rate']})\")\n",
    "print(f\"   Scheduler: CosineAnnealingLR\")\n",
    "print(f\"   Mixed Precision: {config['training']['use_amp']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f61f51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training functions defined\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device, scaler=None):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training', leave=False)\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if scaler:\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config['training']['grad_clip'])\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), config['training']['grad_clip'])\n",
    "            optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc='Validation', leave=False)\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = accuracy_score(all_labels, all_preds)\n",
    "    return epoch_loss, epoch_acc, all_preds, all_labels\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d7f76e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2002594979.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'checkpoint_dir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbest_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpatience_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "os.makedirs(config['paths']['checkpoint_dir'], exist_ok=True)\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_val_acc = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üöÄ STARTING TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Total epochs: {config['training']['epochs']}\")\n",
    "print(f\"Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for epoch in range(config['training']['epochs']):\n",
    "    print(f\"\\nüìÖ Epoch {epoch+1}/{config['training']['epochs']}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, scaler)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc, val_preds, val_labels = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update scheduler\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Store history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'config': config\n",
    "        }, config['paths']['best_model'])\n",
    "        print(f\"‚úÖ Best model saved! Val Acc: {val_acc*100:.2f}%\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"‚è≥ Patience: {patience_counter}/{config['training']['early_stopping_patience']}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= config['training']['early_stopping_patience']:\n",
    "        print(f\"\\n‚ö†Ô∏è Early stopping triggered at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\nüéâ Training completed! Best Val Acc: {best_val_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8294b733",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
